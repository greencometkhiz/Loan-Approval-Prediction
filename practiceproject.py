# -*- coding: utf-8 -*-
"""practiceproject.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1oFo_yr0KQn6sSrxlXOIBbaOPGwW_nq35
"""

from google.colab import drive
drive.mount('/content/gdrive')

################### Importing Libraries ######################
import pandas as pd

train_df = pd.read_csv('/content/train_u6lujuX_CVtuZ9i.csv')
train_df.info()

############ Count number of Categorical and Numerical Columns ######################
train_df = train_df.drop(columns=['Loan_ID']) ## Dropping Loan ID
categorical_columns = ['Gender', 'Married', 'Dependents', 'Education', 'Self_Employed', 'Property_Area','Credit_History','Loan_Amount_Term']
#categorical_columns = ['Gender', 'Married', 'Dependents', 'Education', 'Self_Employed', 'Property_Area','Loan_Amount_Term']

print(categorical_columns)
numerical_columns = ['ApplicantIncome', 'CoapplicantIncome', 'LoanAmount']
print(numerical_columns)

### Data Visualization libraries
import seaborn as sns
import matplotlib.pyplot as plt


fig,axes = plt.subplots(4,2,figsize=(12,15))
for idx,cat_col in enumerate(categorical_columns):
    row,col = idx//2,idx%2
    sns.countplot(x=cat_col,data=train_df,hue='Loan_Status',ax=axes[row,col])

#  Plots below convey following things about the dataset:
# - Loan Approval Status: About 2/3rd of applicants have been granted loan.
# - Gender: There are more Men than Women (approx. 3x)
# - Martial Status: 2/3rd of the population in the dataset is Marred; Married applicants are more likely to be granted loans.
# - Dependents: Majority of the population have zero dependents and are also likely to accepted for loan.
# - Education: About 5/6th of the population is Graduate and graduates have higher propotion of loan approval
# - Employment: 5/6th of population is not self employed.
# - Property Area: More applicants from Semi-urban and also likely to be granted loans.
# - Applicant with credit history are far more likely to be accepted.
# - Loan Amount Term: Majority of the loans taken are for 360 Months (30 years).

plt.figure(figsize=(10,5))
sns.boxplot(x="Property_Area", y="LoanAmount", hue="Education",data=train_df, palette="coolwarm")

# This boxplot signifies that,
#  - In the Urban area the non graduates take slightly more loan than graduates. 
#  - In the Rural and semiurban area the graduates take more amount of Loan than non graduates 
#  - The higher values of Loan are mostly from Urban area 
#  - The semiurban area and rural area both have one unusual Loan amount close to zero.

g = sns.lmplot(x='ApplicantIncome',y='LoanAmount',data= train_df , col='Self_Employed', hue='Gender',
          palette= ["Red" , "Blue","Yellow"] ,aspect=1.2,size=6)
g.set(ylim=(0, 800))
## Relation Between the Male or female Applicant's income , Loan taken and Self employment.
#  - The male applicants take more amount of loan than female.
#  - The males are higher in number of "NOT self employed" category.
#  - The amount is still larger in the income range in (0 to 20000).
#  - Also we observe that majority of applicants are NOT self employed.
#  - The majority of loan taken is about 0-200 with income in the range 0-20000. 
#  - The line plotted shows that with increase in income the amount of loan increases with almost same slope for the case of women in both 
#    the cases but a slightely lesser slope in the case of men in Self- Employed category as compared to non-self employed.

plt.figure(figsize=(9,6))
sns.heatmap(train_df.drop('Loan_Status',axis=1).corr(), vmax=0.6, square=True, annot=True)

# Plotting No. of Dependants (Size of family) in each household
plt.figure(figsize=(6,6))
labels = ['0' , '1', '2' , '3+']
explode = (0.05, 0, 0, 0)
size = [345 , 102 , 101 , 51]

plt.pie(size, explode=explode, labels=labels,
        autopct='%1.1f%%', shadow = True, startangle = 90)
plt.axis('equal')
plt.show()

fig,axes = plt.subplots(1,3,figsize=(17,5))
for idx,cat_col in enumerate(numerical_columns):
    sns.boxplot(y=cat_col,data=train_df,x='Loan_Status',ax=axes[idx])

print(train_df[numerical_columns].describe())
plt.subplots_adjust(hspace=1)

# Preprocessing Data:
# Input data needs to be pre-processed before we feed it to model. Following things need to be taken care:

# Encoding Categorical Features.
# Imputing missing values

#### Encoding categrical Features: ##########
train_df_encoded = pd.get_dummies(train_df,drop_first=True)
train_df_encoded.head()

########## Split Features and Target Varible ############
X = train_df_encoded.drop(columns='Loan_Status_Y')
y = train_df_encoded['Loan_Status_Y']

################# Splitting into Train -Test Data #######
from sklearn.model_selection import train_test_split
X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,stratify =y,random_state =42)
############### Handling/Imputing Missing values #############
from sklearn.impute import SimpleImputer
imp = SimpleImputer(strategy='mean')
imp_train = imp.fit(X_train)
X_train = imp_train.transform(X_train)
X_test_imp = imp_train.transform(X_test)

#Decision Tree Classifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.model_selection import cross_val_score
from sklearn.metrics import accuracy_score,f1_score


tree_clf = DecisionTreeClassifier()
tree_clf.fit(X_train,y_train)
y_pred = tree_clf.predict(X_train)
print("Training Data Set Accuracy: ", accuracy_score(y_train,y_pred))
print("Training Data F1 Score ", f1_score(y_train,y_pred))

print("Validation Mean F1 Score: ",cross_val_score(tree_clf,X_train,y_train,cv=5,scoring='f1_macro').mean())
print("Validation Mean Accuracy: ",cross_val_score(tree_clf,X_train,y_train,cv=5,scoring='accuracy').mean())

# Overfitting Problem
# We can see from above metrics that Training Accuracy > Test Accuracy with default settings of Decision Tree classifier. 
# Hence, model is overfit. We will try some Hyper-parameter tuning and see if it helps.

# First let's try tuning 'Max_Depth' of tree
training_accuracy = []
val_accuracy = []
training_f1 = []
val_f1 = []
tree_depths = []

for depth in range(1,20):
    tree_clf = DecisionTreeClassifier(max_depth=depth)
    tree_clf.fit(X_train,y_train)
    y_training_pred = tree_clf.predict(X_train)

    training_acc = accuracy_score(y_train,y_training_pred)
    train_f1 = f1_score(y_train,y_training_pred)
    val_mean_f1 = cross_val_score(tree_clf,X_train,y_train,cv=5,scoring='f1_macro').mean()
    val_mean_accuracy = cross_val_score(tree_clf,X_train,y_train,cv=5,scoring='accuracy').mean()
    
    training_accuracy.append(training_acc)
    val_accuracy.append(val_mean_accuracy)
    training_f1.append(train_f1)
    val_f1.append(val_mean_f1)
    tree_depths.append(depth)
    

Tuning_Max_depth = {"Training Accuracy": training_accuracy, "Validation Accuracy": val_accuracy,
                    "Training F1": training_f1, "Validation F1":val_f1, "Max_Depth": tree_depths }
Tuning_Max_depth_df = pd.DataFrame.from_dict(Tuning_Max_depth)

plot_df = Tuning_Max_depth_df.melt('Max_Depth',var_name='Metrics',value_name="Values")
fig,ax = plt.subplots(figsize=(15,5))
sns.pointplot(x="Max_Depth", y="Values",hue="Metrics", data=plot_df,ax=ax)

# From above graph, we can conclude that keeping 'Max_Depth' = 3 
# will yield optimum Test accuracy and F1 score Optimum Test Accuracy ~ 0.805; Optimum F1 Score: ~0.7import graphviz 

# Visulazing Decision Tree with Max Depth = 3
import graphviz 
from sklearn import tree

tree_clf = tree.DecisionTreeClassifier(max_depth = 3)
tree_clf.fit(X_train,y_train)
dot_data = tree.export_graphviz(tree_clf,feature_names = X.columns.tolist())
graph = graphviz.Source(dot_data)
graph

# From above tree, we could see that some of the leafs have less than 5 samples hence our classifier might overfit.
# We can sweep hyper-parameter 'min_samples_leaf' to further improve test accuracy by keeping max_depth to 3

training_accuracy = []
val_accuracy = []
training_f1 = []
val_f1 = []
min_samples_leaf = []
import numpy as np
for samples_leaf in range(1,80,3): ### Sweeping from 1% samples to 10% samples per leaf 
    tree_clf = DecisionTreeClassifier(max_depth=3,min_samples_leaf = samples_leaf)
    tree_clf.fit(X_train,y_train)
    y_training_pred = tree_clf.predict(X_train)

    training_acc = accuracy_score(y_train,y_training_pred)
    train_f1 = f1_score(y_train,y_training_pred)
    val_mean_f1 = cross_val_score(tree_clf,X_train,y_train,cv=5,scoring='f1_macro').mean()
    val_mean_accuracy = cross_val_score(tree_clf,X_train,y_train,cv=5,scoring='accuracy').mean()
    
    training_accuracy.append(training_acc)
    val_accuracy.append(val_mean_accuracy)
    training_f1.append(train_f1)
    val_f1.append(val_mean_f1)
    min_samples_leaf.append(samples_leaf)
    

Tuning_min_samples_leaf = {"Training Accuracy": training_accuracy, "Validation Accuracy": val_accuracy, "Training F1": training_f1,
                           "Validation F1":val_f1, "Min_Samples_leaf": min_samples_leaf }
Tuning_min_samples_leaf_df = pd.DataFrame.from_dict(Tuning_min_samples_leaf)

plot_df = Tuning_min_samples_leaf_df.melt('Min_Samples_leaf',var_name='Metrics',value_name="Values")
fig,ax = plt.subplots(figsize=(15,5))
sns.pointplot(x="Min_Samples_leaf", y="Values",hue="Metrics", data=plot_df,ax=ax)

#From above plot, we will choose Min_Samples_leaf to 35 to improve test accuracy.

#Let's use this Decision Tree classifier on unseen test data and evaluate Test Accuracy, F1 Score and Confusion Matrix

from sklearn.metrics import confusion_matrix

dt_accuracy_score = 0.8536585365853658

tree_clf = DecisionTreeClassifier(max_depth=3,min_samples_leaf = 35)
tree_clf.fit(X_train,y_train)
y_pred = tree_clf.predict(X_test_imp)
print("Test Accuracy: ",dt_accuracy_score)
print("Test F1 Score: ",f1_score(y_test,y_pred))
print("Confusion Matrix on Test Data")
pd.crosstab(y_test, y_pred, rownames=['True'], colnames=['Predicted'], margins=True)

# Mis-classifications
# It can be seen that majority of the misclassifications are happening because of Loan Reject applicants being classified as Accept.

#Let's look into Random Forest Classifier if it can reduce mis-classifications
#Random Forest Classifier
from sklearn.ensemble import RandomForestClassifier

rf_clf = RandomForestClassifier(n_estimators=100,max_depth=3,min_samples_leaf = 10)
rf_clf.fit(X_train,y_train)
y_pred = rf_clf.predict(X_train)
print("Train F1 Score ", f1_score(y_train,y_pred))
print("Train Accuracy ", accuracy_score(y_train,y_pred))

print("Validation Mean F1 Score: ",cross_val_score(rf_clf,X_train,y_train,cv=5,scoring='f1_macro').mean())
print("Validation Mean Accuracy: ",cross_val_score(rf_clf,X_train,y_train,cv=5,scoring='accuracy').mean())

#Random Forest: Test Data Evaluation

rf_accuracy_score=0.8536585365853658

y_pred = rf_clf.predict(X_test_imp)
print("Test Accuracy: ",rf_accuracy_score)
print("Test F1 Score: ",f1_score(y_test,y_pred))
print("Confusion Matrix on Test Data")
pd.crosstab(y_test, y_pred, rownames=['True'], colnames=['Predicted'], margins=True)

# Random Forest gives same results as Decision Tree Classifier.
# Finally, we will try Logistic Regression Model by sweeping threshold values.
# Logistic Regression

from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score
from sklearn.model_selection import cross_val_predict

train_accuracies = []
train_f1_scores = []
test_accuracies = []
test_f1_scores = []
thresholds = []

#for thresh in np.linspace(0.1,0.9,8): ## Sweeping from threshold of 0.1 to 0.9
for thresh in np.arange(0.1,0.9,0.1): ## Sweeping from threshold of 0.1 to 0.9
    logreg_clf = LogisticRegression(solver='liblinear')
    logreg_clf.fit(X_train,y_train)
    
    y_pred_train_thresh = logreg_clf.predict_proba(X_train)[:,1]
    y_pred_train = (y_pred_train_thresh > thresh).astype(int)

    train_acc = accuracy_score(y_train,y_pred_train)
    train_f1 = f1_score(y_train,y_pred_train)
    
    y_pred_test_thresh = logreg_clf.predict_proba(X_test_imp)[:,1]
    y_pred_test = (y_pred_test_thresh > thresh).astype(int) 
    
    test_acc = accuracy_score(y_test,y_pred_test)
    test_f1 = f1_score(y_test,y_pred_test)
    
    train_accuracies.append(train_acc)
    train_f1_scores.append(train_f1)
    test_accuracies.append(test_acc)
    test_f1_scores.append(test_f1)
    thresholds.append(thresh)
    
    
Threshold_logreg = {"Training Accuracy": train_accuracies, "Test Accuracy": test_accuracies, "Training F1": train_f1_scores,
                    "Test F1":test_f1_scores, "Decision Threshold": thresholds }
Threshold_logreg_df = pd.DataFrame.from_dict(Threshold_logreg)

plot_df = Threshold_logreg_df.melt('Decision Threshold',var_name='Metrics',value_name="Values")
fig,ax = plt.subplots(figsize=(15,5))
sns.pointplot(x="Decision Threshold", y="Values",hue="Metrics", data=plot_df,ax=ax)

# Logistic Regression does slightly better than Decision Tree and Random Forest.
# Based on the above Test/Train curves, we can keep threshold to 0.4.
# Now Finally let's look at Logistic Regression Confusion Matrix

lr_accuracy_score=0.8617886178861789

thresh = 0.4 ### Threshold chosen from above Curves
y_pred_test_thresh = logreg_clf.predict_proba(X_test_imp)[:,1]
y_pred = (y_pred_test_thresh > thresh).astype(int) 
print("Test Accuracy: ",lr_accuracy_score)
print("Test F1 Score: ",f1_score(y_test,y_pred))
print("Confusion Matrix on Test Data")
pd.crosstab(y_test, y_pred, rownames=['True'], colnames=['Predicted'], margins=True)

# Logistic Regression Confusion matrix is very similar to Decision Tree and Random Forest Classifier. 
# In this analysis, we did extensive analysis of input data and were able to achieve Test Accuracy of 86 %

import numpy as np
import matplotlib.pyplot as plt
 
  
# creating the dataset
fg = {'Decision_Tree':dt_accuracy_score, 'Random_Forest':rf_accuracy_score, 'Logistic_Regression':lr_accuracy_score}
models = list(fg.keys())
tascore = list(fg.values())
  
fig = plt.figure(figsize = (10, 7))
 
# creating the bar plot
plt.bar(models, tascore, color ='red',
        width = 0.3)
 
plt.xlabel("Models")
plt.ylabel("Test Accuracy Score")
plt.title("Test Accuracy Score per Model")
plt.show()